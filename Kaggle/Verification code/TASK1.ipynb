{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM9lwFUo1ede1/mL2HYqYiX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install kaggle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQGLIm5G8tAH","executionInfo":{"status":"ok","timestamp":1684513695336,"user_tz":-480,"elapsed":5894,"user":{"displayName":"Xun","userId":"06490221290545862253"}},"outputId":"e12fd9fd-07df-4956-c79b-0909e90b0d79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qTMyY37e-E8T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684514420005,"user_tz":-480,"elapsed":24795,"user":{"displayName":"Xun","userId":"06490221290545862253"}},"outputId":"18a904c2-d005-423f-9136-57e6a84eaa29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["! mkdir ~/.kaggle\n","! cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/\n","! chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"kIAIQ4fyVDcP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNIMhwe78V3g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684514527313,"user_tz":-480,"elapsed":5535,"user":{"displayName":"Xun","userId":"06490221290545862253"}},"outputId":"eff734a4-2997-4334-dcf6-a4fcaf8e423a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading captcha-hacker-2023-spring.zip to /content\n"," 96% 76.0M/79.4M [00:03<00:00, 19.7MB/s]\n","100% 79.4M/79.4M [00:03<00:00, 21.5MB/s]\n"]}],"source":["!kaggle competitions download -c captcha-hacker-2023-spring"]},{"cell_type":"code","source":["!unzip captcha-hacker-2023-spring.zip"],"metadata":{"id":"fPF8pa9wTblC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","import cv2\n","import numpy as np\n","import random\n","import os\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder"],"metadata":{"id":"orNMgN76Zfkr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TRAIN_PATH = \"/content/dataset/train\"\n","TEST_PATH = \"/content/dataset/test\"\n","TASK1 = '/task1'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"VOLj43gLNonv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alphabets = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\" # 62\n","alphabets2index = {alphabet:i for i, alphabet in enumerate(alphabets)}"],"metadata":{"id":"o-YIgZeUFliB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 去除雜訊\n","\n","import random\n","import glob\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","\n","from google.colab.patches import cv2_imshow\n","\n","folder_path = TRAIN_PATH + TASK1\n","\n","file_path = glob.glob(folder_path + '/*.png')\n","                                                            \n","# 產生一個隨機整數\n","random_int = random.randint(0, len(file_path))\n","\n","# 載入圖像並將其轉換為灰度圖\n","image = cv2.imread(file_path[random_int])\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","# 對圖像進行二值化處理（轉換為純黑白）\n","thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n","\n","# 將上下左右的5個像素轉換為黑色\n","thresh[-5:5, :] = 0  # 上下方5個像素設為黑色\n","thresh[:, -5:5] = 0  # 左右側5個像素設為黑色\n","\n","kernel = np.ones((3, 3))\n","\n","# 侵蝕\n","thresh = cv2.erode(thresh, kernel=kernel, iterations=1)\n","# 膨脹\n","thresh = cv2.dilate(thresh, kernel=kernel, iterations=1)\n","\n","# 顯示圖像\n","# cv2_imshow(thresh)"],"metadata":{"id":"f9AzR-ENgR3i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def compute_mean_std(dataset):\n","#     # 計算平均值和標準差\n","#     mean = torch.zeros(3)\n","#     std = torch.zeros(3)\n","\n","#     for images, _ in dataset:\n","#         mean += torch.mean(images, dim=[1, 2])\n","#         std += torch.std(images, dim=[1, 2])\n","\n","#     mean /= len(dataset)\n","#     std /= len(dataset)\n","\n","#     return mean, std\n","\n","# # 創建 ImageFolder 數據集對象\n","# transform = transforms.Compose([transforms.ToTensor()])\n","# dataset = ImageFolder(root=TRAIN_PATH, transform=transform)\n","\n","# # 計算平均值和標準差\n","# mean, std = compute_mean_std(dataset)\n","\n","# print(\"平均值:\", mean)\n","# print(\"標準差:\", std)"],"metadata":{"id":"XIbabIOXhO5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Task3Dataset(Dataset):\n","    def __init__(self, data, root, return_filename=False):\n","        self.data = [sample for sample in data if sample[0].startswith(\"task3\")] # 從csv檔案取出\n","        self.root = root\n","        self.transform = transforms.Compose([\n","            transforms.Resize((96, 96)),\n","            transforms.RandomAffine(30, (0.1, 0.1)),\n","            transforms.ToTensor()\n","        ])\n","        self.return_filename = return_filename\n","    \n","    def __getitem__(self, index):\n","        filename, label = self.data[index]\n","\n","        # 載入圖像並將其轉換為灰度圖\n","        image = cv2.imread(f\"{self.root}/{filename}\")\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        # 對圖像進行二值化處理（轉換為純黑白）\n","        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n","\n","        # 將上下左右的5個像素轉換為黑色\n","        thresh[-5:5, :] = 0  # 上下方5個像素設為黑色\n","        thresh[:, -5:5] = 0  # 左右側5個像素設為黑色\n","\n","        kernel = np.ones((3, 3))\n","\n","        # 侵蝕\n","        thresh = cv2.erode(thresh, kernel=kernel, iterations=1)\n","        # 膨脹\n","        thresh = cv2.dilate(thresh, kernel=kernel, iterations=1)\n","\n","        # img = Image.open(f\"{self.root}/{filename}\").convert(\"L\")\n","\n","        # 將numpy.ndarray轉換為PIL.Image.Image類型\n","        pil_image = Image.fromarray(thresh)\n","\n","        img = self.transform(pil_image)\n","\n","        label = torch.tensor([alphabets2index[x] for x in list(label)])\n","        \n","        if self.return_filename:\n","          \n","          return img, filename\n","\n","        else:\n","\n","          return img, label\n","\n","    def __len__(self):\n","        return len(self.data)"],"metadata":{"id":"ihxKtoOcIMXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self, num_classes):\n","        super(Model, self).__init__()\n","        self.feature_extractor = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding='same'),\n","            nn.BatchNorm2d(num_features=16),\n","            nn.ReLU(),\n","            nn.Conv2d(16, 16, kernel_size=3, padding='same'),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","\n","            nn.Conv2d(16, 32, kernel_size=3, padding='same'),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 32, kernel_size=3, padding='same'),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","\n","            nn.Conv2d(32, 64, kernel_size=3, padding='same'),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 64, kernel_size=3, padding='same'),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","        \n","        self.classifier = nn.Sequential(\n","            nn.AdaptiveAvgPool2d(1),\n","            nn.Flatten(),\n","            nn.Linear(64, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.feature_extractor(x)\n","        x = self.classifier(x)\n","        \n","        return x\n","\n","# # 建立模型\n","# model = Model(len(alphabets2index)).to(device)\n","\n","# from torchsummary import summary\n","\n","# # 輸出模型摘要\n","# summary(model, input_size=(1, 96, 96), batch_size=-1, device=device)\n"],"metadata":{"id":"FakeqLcsGOHG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data, val_data = [], []\n","\n","# 隨機取樣\n","with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n","    for row in csv.reader(csvfile, delimiter=','):\n","        if random.random() < 0.8:\n","            train_data.append(row)\n","        else:\n","            val_data.append(row)\n","\n","train_dataset = Task1Dataset(train_data, root=TRAIN_PATH)\n","train_Loader = DataLoader(train_dataset, batch_size=16, num_workers=2, drop_last=True, shuffle=True)\n","\n","val_dataset = Task1Dataset(val_data, root=TRAIN_PATH)\n","val_Loader = DataLoader(val_dataset, batch_size=20, num_workers=2, drop_last=False, shuffle=False)"],"metadata":{"id":"m-eom28xOJaz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EarlyStoppingCallback:\n","    def __init__(self, patience=10):\n","        self.patience = patience  # 最大等待改善的訓練輪數\n","        self.counter = 0  # 紀錄連續沒有改善的輪數\n","        self.best_accuracy = 0.0  # 目前最佳的準確率\n","        self.stop_training = False  # 用於停止訓練迴圈\n","\n","    def __call__(self, model, accuracy):\n","\n","        if accuracy > self.best_accuracy:  # 檢查目前的準確率是否優於目前最佳準確率\n","            self.best_accuracy = accuracy  # 更新最佳準確率\n","            self.counter = 0  # 重設計數器\n","            torch.save(model.state_dict(), \"best_model.pt\")  # 儲存模型\n","            print(\"已保存最佳模型。\")\n","        else:\n","            self.counter += 1  # 增加計數器，因為沒有改善\n","\n","        if self.counter >= self.patience:  # 檢查計數器是否超過等待改善的輪數\n","            print(\"觸發提前停止。\")\n","            self.stop_training = True"],"metadata":{"id":"rV4PWkN7V2qX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Model(len(alphabets2index)).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# 創建自定義回調函數實例\n","callback = EarlyStoppingCallback(patience=10)\n","\n","for epoch in range(30):\n","    print(f\"Epoch [{epoch}]\")\n","    model.train()\n","\n","    for image, label in train_Loader:\n","        image = image.to(device)\n","        label = label.to(device)\n","\n","        pred = model(image)\n","\n","        loss = loss_fn(pred, label)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    model.eval()\n","        \n","    sample_count = 0\n","    correct_count = 0\n","\n","    for image, label in val_Loader:\n","        image = image.to(device)\n","        label = label.to(device)\n","        \n","        pred = model(image)\n","        loss = loss_fn(pred, label)\n","        \n","        pred = torch.argmax(pred, dim=1)\n","        \n","        sample_count += len(image)\n","        correct_count += (label == pred).sum()\n","\n","        accuracy = correct_count / sample_count\n","        \n","    print(\"accuracy (validation):\", accuracy)\n","\n","    # 在每個 epoch 結束後調用檢查準確率\n","    callback(model, accuracy)\n","\n","    if callback.stop_training:\n","      break"],"metadata":{"id":"grE7cJbYOTmd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = []\n","with open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n","    for row in csv.reader(csvfile, delimiter=','):\n","        test_data.append(row)\n","\n","test_dataset = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\n","test_Loader = DataLoader(test_dataset, batch_size=500, num_workers=4, drop_last=False, shuffle=False)\n","\n","# 使否存在，否則創建\n","if os.path.exists('submission.csv'):\n","    csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\n","else:\n","    csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n","    csv_writer.writerow([\"filename\", \"label\"])\n","\n","\n","model.eval()\n","for image, filenames in test_Loader:\n","    image = image.to(device)\n","    \n","    pred = model(image)\n","    pred = torch.argmax(pred, dim=1)\n","    \n","    for i in range(len(filenames)):\n","        csv_writer.writerow([filenames[i], alphabets[pred[i].item()]])\n","\n","for filename, _ in test_data:\n","    if filename.startswith(\"task2\") or filename.startswith(\"task3\"):\n","        csv_writer.writerow([filename, 0])"],"metadata":{"id":"-u3AGykCOWy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ljbNj5IJJ-PA"},"execution_count":null,"outputs":[]}]}